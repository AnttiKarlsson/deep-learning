# General Domain Portuguese Language Model

This is an on-going language model implementation for Portuguese (Wikipedia based corpus).  

- AWD-LSTM based architecture <a href="#DBLP58journals47corr47abs4517084502182">[3]</a>
- Vocabulary size: 30,000 words

## References
1. <a id="DBLP58journals47corr47abs4518014506146"></a>Jeremy Howard and Sebastian Ruder. Fine-tuned Language Models for Text Classification. 2018
2. <a id="DBLP58journals47corr47abs4518034509820"></a>Leslie N. Smith. A disciplined approach to neural network hyper-parameters: Part 1 - learning rate, batch size, momentum, and weight decay. 2018
3. <a id="DBLP58journals47corr47abs4517084502182"></a>Stephen Merity, Nitish Shirish Keskar and Richard Socher. Regularizing and Optimizing LSTM Language Models. 2017
